{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#n-gram-use\" data-toc-modified-id=\"n-gram-use-0.0.0.1\"><span class=\"toc-item-num\">0.0.0.1&nbsp;&nbsp;</span>n-gram use</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Using-our-own-perceptron\" data-toc-modified-id=\"Using-our-own-perceptron-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Using our own perceptron</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sklearn.datasets.fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip scikit-learn\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130107"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'icts01': 65607,\n",
       " 'obfusc': 88981,\n",
       " 'ashby': 29701,\n",
       " 'chzd2': 39748,\n",
       " 'gathic': 58258,\n",
       " 'victories': 121445,\n",
       " '3170': 11604,\n",
       " 'murray_craven': 84969,\n",
       " 'rosenblatt': 102973,\n",
       " 'organised': 90373,\n",
       " '___no': 23419,\n",
       " 'w1m': 122618,\n",
       " 'alderson': 27294,\n",
       " 's3saturn': 103978,\n",
       " 'ammend': 27892,\n",
       " 'uw1': 120043,\n",
       " 'speech': 109306,\n",
       " '1dofcl': 6773,\n",
       " 'lumberjacks': 77276,\n",
       " 'abt': 25489,\n",
       " 'theogony': 114534,\n",
       " 'vermillion': 121201,\n",
       " 'oscs': 90595,\n",
       " 'ryanph': 103738,\n",
       " '90rwsl1a': 21549,\n",
       " 'kanata': 71738,\n",
       " 'sj1rcho': 107728,\n",
       " 'metallibashers': 81320,\n",
       " '6h2': 17665,\n",
       " 'upsets': 119544,\n",
       " 'ballard': 31662,\n",
       " 'koppel': 73393,\n",
       " 'bombards': 34294,\n",
       " 'solaris2': 108713,\n",
       " '3en8h3': 12738,\n",
       " '123539': 3567,\n",
       " 'kranz': 73571,\n",
       " 'rescheduling': 101178,\n",
       " 'fascicularis_': 54444,\n",
       " 'appropriate': 28960,\n",
       " 'piacenza': 93731,\n",
       " 'uv': 120014,\n",
       " 'v9f9f9f9f9fq': 120455,\n",
       " 'abott': 25393,\n",
       " '8cfiyn': 20898,\n",
       " 'scholieren': 105176,\n",
       " '052552': 1089,\n",
       " 'orplqwtu': 90502,\n",
       " 'z6q': 128903,\n",
       " 'xcopyplane': 126230,\n",
       " 'v4e': 120313,\n",
       " 'profits': 96179,\n",
       " 'eec': 50566,\n",
       " 'fyn2tm': 57545,\n",
       " 'g3o': 57710,\n",
       " 'gandhi': 58097,\n",
       " 'uwf': 120077,\n",
       " 'rushdie': 103554,\n",
       " 'roadrunners': 102616,\n",
       " '4deq': 14297,\n",
       " '931': 21799,\n",
       " '45432': 13788,\n",
       " 'wheaties': 124006,\n",
       " 'cup9i': 44068,\n",
       " 'preferred': 95625,\n",
       " 'related': 100633,\n",
       " 'bli': 33815,\n",
       " 'b62': 31156,\n",
       " 'slander': 107984,\n",
       " 'spork': 109574,\n",
       " 'abovew': 25405,\n",
       " 'xv': 127361,\n",
       " 'wksa16': 124715,\n",
       " 'mazilli': 80040,\n",
       " 'p04': 91301,\n",
       " 'sweating': 112329,\n",
       " 'aplogize': 28749,\n",
       " 'res': 101169,\n",
       " 'wa85': 122966,\n",
       " 'monitor': 83517,\n",
       " '195710': 6376,\n",
       " 'scrubbers': 105480,\n",
       " 'y26cn': 127639,\n",
       " '1qv83m': 7771,\n",
       " 'adaptecs': 26032,\n",
       " 'qqzrpo': 98034,\n",
       " 'combs': 41143,\n",
       " 'srr': 109923,\n",
       " 'pedophile': 92749,\n",
       " 'chandeliers': 38977,\n",
       " '190846': 6170,\n",
       " 's0ta33pa84ta86': 103832,\n",
       " 'relates': 100635,\n",
       " 'da59b': 44816,\n",
       " 'verboseness': 121149,\n",
       " 'choqvf1': 39528,\n",
       " 'daffy': 44860,\n",
       " '8un': 21332,\n",
       " 'vests': 121289,\n",
       " 'edb9140': 50434,\n",
       " 'orlhod': 90459,\n",
       " 'hoffmeister': 63678,\n",
       " 'prescience': 95718,\n",
       " '734864478': 18666,\n",
       " 'qst44': 98152,\n",
       " 'bvz': 35905,\n",
       " 'envolved': 52000,\n",
       " 'skvh': 107912,\n",
       " 'libya': 75766,\n",
       " 'mecr6eft': 80778,\n",
       " 'movies': 83998,\n",
       " 'wagner': 123036,\n",
       " 'ruskin': 103562,\n",
       " 'walked': 123105,\n",
       " 'ahh': 26834,\n",
       " '100387': 2465,\n",
       " 'leech': 75125,\n",
       " 'ction': 43904,\n",
       " 'steve_mullins': 110625,\n",
       " 'purses': 97092,\n",
       " 'cx7pe1f6': 44292,\n",
       " 'eqm': 52166,\n",
       " 'z75vz': 128922,\n",
       " 'petrich': 93291,\n",
       " 'compare173': 41364,\n",
       " 'ce9': 38508,\n",
       " 'laten': 74696,\n",
       " 'id2': 65626,\n",
       " 'shrewsbury': 107087,\n",
       " 'sla': 107958,\n",
       " 'congresswoman': 41949,\n",
       " '4sxjizsg': 14705,\n",
       " 'jcv': 69682,\n",
       " 'r30gno': 98707,\n",
       " 'monomethyl': 83546,\n",
       " 'jacoby': 69397,\n",
       " 'perdre': 92968,\n",
       " '15': 4605,\n",
       " 'tongues': 115641,\n",
       " 'hr3hkgbe': 64395,\n",
       " 'warlords': 123241,\n",
       " 'insturment': 67635,\n",
       " 'phurchase': 93678,\n",
       " 'hzai': 65016,\n",
       " 'h1p4s4g': 61233,\n",
       " 'appropriateness': 28963,\n",
       " 'tatarinov': 113543,\n",
       " 'irb': 68398,\n",
       " 'darryl': 45100,\n",
       " 'yuggoth': 128587,\n",
       " 'downsizing': 48785,\n",
       " 'ncc': 86318,\n",
       " 'ggpc': 58949,\n",
       " 'und2dzd': 118542,\n",
       " 'moth': 83853,\n",
       " '734553308snx': 18623,\n",
       " 'uw1471': 120048,\n",
       " 'sg48': 106430,\n",
       " '_v_x': 24524,\n",
       " '94124': 22032,\n",
       " 'kwnk': 73911,\n",
       " 'abusers': 25502,\n",
       " 's7': 104070,\n",
       " 'noncareer': 87735,\n",
       " 'pygmalion': 97274,\n",
       " 'o92a': 88845,\n",
       " 'zy5': 130042,\n",
       " 'xada': 126097,\n",
       " '4fvk': 14374,\n",
       " 'powerusersgroupchairman': 95296,\n",
       " 'chun': 39693,\n",
       " 'kjrnl': 72906,\n",
       " 'palpitations': 91819,\n",
       " 'my_default_bg_color': 85365,\n",
       " 'reaches': 99736,\n",
       " 'doubly': 48703,\n",
       " 'mayer': 80012,\n",
       " 'ksiv': 73694,\n",
       " '7095': 18276,\n",
       " 'morekypr': 83716,\n",
       " 'the_display': 114458,\n",
       " 'i0ws': 65122,\n",
       " 'znkjr': 129626,\n",
       " 'buenneke': 35472,\n",
       " 'negotating': 86545,\n",
       " 'mjjjjn': 82687,\n",
       " 'rm0h23tc': 102446,\n",
       " '2262': 9126,\n",
       " 'computation': 41607,\n",
       " 'catnip': 38164,\n",
       " 'lwnuzh': 77434,\n",
       " 'damien': 44941,\n",
       " 'monomolecular': 83547,\n",
       " 'chosen': 39546,\n",
       " 'dogan': 48456,\n",
       " 'luq': 77331,\n",
       " 'k51': 71437,\n",
       " '4yav': 14852,\n",
       " 'disasterous': 47515,\n",
       " 'markov': 79542,\n",
       " 'yw6': 128669,\n",
       " 'siegel': 107283,\n",
       " 'iuko': 68907,\n",
       " 'schoene': 105164,\n",
       " 'u1s8jafrq': 117456,\n",
       " 'y44': 127665,\n",
       " 'vpbuild': 122165,\n",
       " 'keck': 72112,\n",
       " 'pom': 94901,\n",
       " '15028': 4621,\n",
       " 'contextual': 42285,\n",
       " 'gayri': 58313,\n",
       " 'k0e': 71325,\n",
       " '_u2': 24499,\n",
       " 'hatin': 62180,\n",
       " 'defragger': 45967,\n",
       " 'come': 41148,\n",
       " 'pulkka': 96931,\n",
       " 'rosters': 103009,\n",
       " 'concern': 41696,\n",
       " 'zx8': 130024,\n",
       " 'tercel': 114127,\n",
       " 'p0n': 91312,\n",
       " 'xcmstekhvcqueryminv': 126217,\n",
       " 'qrp': 98054,\n",
       " '7yz': 19983,\n",
       " 'c5g4mm': 36546,\n",
       " 'handshaking': 61861,\n",
       " 'positives': 95101,\n",
       " 'increments': 66815,\n",
       " 'vyo5j': 122520,\n",
       " 'taubensee': 113567,\n",
       " 'offset': 89433,\n",
       " '534': 15199,\n",
       " 'lutrepulse': 77368,\n",
       " '0493': 1026,\n",
       " 'wtem': 125396,\n",
       " 'uaris4u': 117727,\n",
       " 'hotdoggers': 64113,\n",
       " 'sort_method': 108932,\n",
       " 'reksa': 100624,\n",
       " 'laibach': 74412,\n",
       " 'megatonnes': 80907,\n",
       " 'luparas': 77326,\n",
       " '0g12o': 1762,\n",
       " 'laughing': 74745,\n",
       " '0bz': 1639,\n",
       " 'i_n1_': 65362,\n",
       " 'rests': 101421,\n",
       " 'netzer': 86763,\n",
       " 'mjjjjht': 82681,\n",
       " '7w2c': 19938,\n",
       " 'biotics': 33472,\n",
       " '0spqw': 2099,\n",
       " '_need_': 24121,\n",
       " 'r6hmk7': 98809,\n",
       " 'distributed': 47978,\n",
       " '34jf4': 12004,\n",
       " '12n': 3782,\n",
       " 'works': 125042,\n",
       " 'fid3hw': 55197,\n",
       " 'grandslam': 60112,\n",
       " '13389': 3960,\n",
       " 'q24a': 97385,\n",
       " 'cordless': 42634,\n",
       " 'herzog': 62911,\n",
       " 'indepedent': 66855,\n",
       " 'communion': 41319,\n",
       " 'p6x': 91478,\n",
       " 'n1pl': 85632,\n",
       " 'guardia': 60763,\n",
       " 'wacks': 122995,\n",
       " '56j': 15514,\n",
       " 'mnxrx': 83173,\n",
       " 'intensify': 67727,\n",
       " '3hzrchz': 12874,\n",
       " 'astounding': 29968,\n",
       " '594': 15687,\n",
       " 'drafting': 48896,\n",
       " 'typetype': 117309,\n",
       " 'mcmath': 80429,\n",
       " 'genenius': 58589,\n",
       " 'damnable': 44945,\n",
       " 'spearmen': 109218,\n",
       " 'provisios': 96584,\n",
       " 'irritate': 68512,\n",
       " 'tasp': 113532,\n",
       " 'lbli': 74902,\n",
       " 'e21h1': 49844,\n",
       " 'napoleonic': 86059,\n",
       " 'smm': 108345,\n",
       " 'shootout': 106962,\n",
       " 'sovereign': 109017,\n",
       " '7pry': 19777,\n",
       " 'habitation': 61515,\n",
       " 'ufrgs': 117982,\n",
       " '0xa7': 2275,\n",
       " 'osy': 90667,\n",
       " 'pierrepoint': 93819,\n",
       " 'shz04': 107174,\n",
       " 'ailab': 26913,\n",
       " 'catastrophes': 38106,\n",
       " 'dry': 49149,\n",
       " 'belated': 32621,\n",
       " 'negative': 86523,\n",
       " 'mu3': 84654,\n",
       " 'torque': 115772,\n",
       " 'trick': 116474,\n",
       " 'unpunched': 119157,\n",
       " 'prez': 95873,\n",
       " 'crying': 43681,\n",
       " 'disputes': 47863,\n",
       " 'lyid': 77491,\n",
       " 'iv755': 68924,\n",
       " 'three': 114844,\n",
       " 'loke': 76660,\n",
       " 'tumble': 116950,\n",
       " 'psweeney': 96739,\n",
       " 'qhwjh': 97798,\n",
       " 'qucdn': 98326,\n",
       " 'program': 96197,\n",
       " 'clari': 40214,\n",
       " '275': 10077,\n",
       " '1344': 3974,\n",
       " '0otv': 1986,\n",
       " '1oz': 7108,\n",
       " 'mercutio': 81183,\n",
       " 'mbp': 80128,\n",
       " 'dik': 47281,\n",
       " 'taco': 113189,\n",
       " 'mcdonald': 80307,\n",
       " 'bowler': 34608,\n",
       " 'samsung': 104523,\n",
       " '87lzv': 20649,\n",
       " 'cyclamates': 44422,\n",
       " 'aspromonte': 29796,\n",
       " 'acs5': 25902,\n",
       " 'sorry': 108930,\n",
       " 'enticement': 51901,\n",
       " 'collected': 40985,\n",
       " 'licking': 75789,\n",
       " 'apostacy': 28792,\n",
       " 'mordor': 83704,\n",
       " '3d0': 12662,\n",
       " '272007': 10039,\n",
       " 'ewell': 53063,\n",
       " 'constructor': 42189,\n",
       " 'doughter': 48727,\n",
       " 'beav133': 32405,\n",
       " '23256': 9303,\n",
       " 'sof': 108650,\n",
       " 'spacify': 109096,\n",
       " 'jp2': 70662,\n",
       " 'nicer': 87175,\n",
       " '5ut770fnki': 16343,\n",
       " 'inflame': 67123,\n",
       " 'wdatxt': 123546,\n",
       " '1483500354': 4536,\n",
       " 'it2i2x': 68770,\n",
       " 'marquees': 79581,\n",
       " 'shostack': 107012,\n",
       " 'defences': 45877,\n",
       " 'darcym': 45048,\n",
       " 'georgeous': 58746,\n",
       " 'ttyl': 116871,\n",
       " 'helmetted': 62692,\n",
       " 'e1w2': 49839,\n",
       " 'znajrnair': 129571,\n",
       " '526175': 15136,\n",
       " 'elder': 50994,\n",
       " 'xl71xu': 126600,\n",
       " 'gdw0cn': 58458,\n",
       " 'horses_': 64055,\n",
       " 'ucbx': 117796,\n",
       " 'kass': 71873,\n",
       " 'skriko': 107899,\n",
       " 'ol7z': 89667,\n",
       " 'replug': 101032,\n",
       " 'yearwood': 128030,\n",
       " 'pshanley': 96693,\n",
       " 'k044477': 71322,\n",
       " 'ausvm1': 30464,\n",
       " '1f9f9f9f9f9f8': 6847,\n",
       " 'pnewwiz': 94644,\n",
       " 'vesta': 121282,\n",
       " 'u4n8a': 117544,\n",
       " 'judenrein': 70932,\n",
       " 'close': 40496,\n",
       " 'j27t': 69117,\n",
       " 'stevef': 110632,\n",
       " 'vents': 121116,\n",
       " 'thati': 114445,\n",
       " 'm484g': 77975,\n",
       " 's386': 103948,\n",
       " 'cheerful': 39199,\n",
       " 'pwu8': 97225,\n",
       " 'sequitur': 106168,\n",
       " 'tolled': 115570,\n",
       " 'jxl9011': 71203,\n",
       " '1040': 2701,\n",
       " 'pi6c': 93728,\n",
       " 'priam': 95880,\n",
       " '1869': 6050,\n",
       " 'nr8': 88136,\n",
       " 'wittgenstein': 124666,\n",
       " 'sdcc13': 105571,\n",
       " 'pyro': 97291,\n",
       " 'eyn1': 53700,\n",
       " 'h16': 61219,\n",
       " '115331': 3238,\n",
       " '2t555l': 11183,\n",
       " 'sevaxu': 106328,\n",
       " 'mittelst': 82583,\n",
       " 'corrados': 42722,\n",
       " '38kjuufu': 12480,\n",
       " 'mosters': 83839,\n",
       " 'mchz': 80383,\n",
       " '9865': 22384,\n",
       " 'm084ta1': 77593,\n",
       " 'expire': 53439,\n",
       " '10b': 2865,\n",
       " 'temporal': 114025,\n",
       " 'eden': 50443,\n",
       " 'fateman': 54495,\n",
       " 'foote': 56257,\n",
       " '4h7': 14409,\n",
       " '4916384': 14128,\n",
       " '9801': 22350,\n",
       " 'kearns': 72106,\n",
       " 'copywrited': 42611,\n",
       " '_o6n_o': 24156,\n",
       " 'bakis': 31610,\n",
       " 'c4yth2uqz': 36330,\n",
       " 'mw': 85182,\n",
       " '8764': 20622,\n",
       " 'azcc': 30942,\n",
       " 'annoyning': 28377,\n",
       " 'jur4eev': 71052,\n",
       " 'subharmonic': 111318,\n",
       " 'ishin': 68590,\n",
       " 'regy105': 100507,\n",
       " 'iqr': 68328,\n",
       " 'iskandar': 68607,\n",
       " '295': 10455,\n",
       " 'tricity': 116473,\n",
       " 'patronized': 92400,\n",
       " 'fehrabend': 54802,\n",
       " 'outlets': 90832,\n",
       " 'relic': 100696,\n",
       " 'ancestors': 28132,\n",
       " 'territoriesd': 114200,\n",
       " 'ko2eqr': 73245,\n",
       " 'hemoraging': 62742,\n",
       " 'mmfu': 82984,\n",
       " 'pnw': 94657,\n",
       " 'tercels': 114128,\n",
       " 'staggered': 110162,\n",
       " 'elvex33': 51245,\n",
       " 'dmcaloon': 48258,\n",
       " 'stainless': 110174,\n",
       " 'lyq': 77532,\n",
       " 'umsmith': 118325,\n",
       " 'hampton': 61783,\n",
       " 'richtofen': 101913,\n",
       " 'loc': 76539,\n",
       " 'tasc': 113517,\n",
       " 'uniforms': 118865,\n",
       " 'motocycle': 83891,\n",
       " 'preston': 95791,\n",
       " 'rzi9': 103790,\n",
       " 'tvv': 117120,\n",
       " 'sparcstations': 109150,\n",
       " 'h0o': 61204,\n",
       " 'lenient': 75305,\n",
       " 'kd4qlz': 72064,\n",
       " 'jelinek': 69819,\n",
       " 'exegesis': 53258,\n",
       " 'rn6v': 102538,\n",
       " '28i': 10346,\n",
       " 'defenant': 45872,\n",
       " 'ijn': 66049,\n",
       " 'confusing': 41914,\n",
       " '1wb': 8145,\n",
       " 'fsazge': 57075,\n",
       " 'kweqq': 73901,\n",
       " 'xtpeekevent': 127253,\n",
       " 'au021': 30304,\n",
       " 'honestlyhave': 63897,\n",
       " 'face': 54092,\n",
       " 'minor': 82287,\n",
       " '1122': 3113,\n",
       " '943': 22040,\n",
       " 'sunburns': 111745,\n",
       " '_clementine': 23631,\n",
       " '2110': 8685,\n",
       " 'boleslaw': 34261,\n",
       " 'puhj88h': 96914,\n",
       " 'zebedee': 129225,\n",
       " '6ei0nei': 17513,\n",
       " '12407': 3588,\n",
       " 'buckner': 35429,\n",
       " '1pik3i': 7182,\n",
       " 'continuum': 42312,\n",
       " 'cui': 44004,\n",
       " 't9q58sbi': 113090,\n",
       " '142415': 4266,\n",
       " 'ee0i': 50552,\n",
       " 'micronews': 81892,\n",
       " 'out': 90774,\n",
       " 'attacker': 30208,\n",
       " 'stagger': 110161,\n",
       " '4lm': 14500,\n",
       " 'alatalo': 27240,\n",
       " 'column': 41098,\n",
       " 'people': 92923,\n",
       " '4hznw39': 14421,\n",
       " '01011010b': 399,\n",
       " 'rogerskm': 102796,\n",
       " 'n1fnb5': 85617,\n",
       " 'l7y': 74217,\n",
       " 'microcenter': 81843,\n",
       " 'ry2vl': 103729,\n",
       " 'opposes': 90132,\n",
       " 'asrlk': 29808,\n",
       " 'forehead': 56330,\n",
       " 'warheads': 123233,\n",
       " 'nwk': 88501,\n",
       " 'days': 45311,\n",
       " '084236': 1431,\n",
       " 'howtosit': 64211,\n",
       " 'pao': 91918,\n",
       " 'bothell': 34526,\n",
       " 'dck': 45413,\n",
       " 'reinserted': 100571,\n",
       " '1400k': 4160,\n",
       " 'caleb': 37385,\n",
       " 'gfp': 58910,\n",
       " 'surly': 112065,\n",
       " 'whistle': 124093,\n",
       " 'o1v': 88683,\n",
       " 'oriental': 90410,\n",
       " 'bargin': 31844,\n",
       " 'm08i': 77596,\n",
       " 'whacking': 123964,\n",
       " '_9uw3': 23311,\n",
       " 'ttu': 116864,\n",
       " 'general': 58594,\n",
       " 'hooey': 63934,\n",
       " '8693': 20567,\n",
       " 'unusual': 119359,\n",
       " 'carelessly': 37855,\n",
       " '1212': 3478,\n",
       " 'observance': 89068,\n",
       " 'lockheed': 76569,\n",
       " 'nkm': 87520,\n",
       " 'firepower': 55504,\n",
       " 'qhf': 97782,\n",
       " 'dtu': 49291,\n",
       " 'canst': 37673,\n",
       " 'k8z': 71562,\n",
       " 'memoire': 81052,\n",
       " 'glocks': 59420,\n",
       " 'bor': 34426,\n",
       " 'backlit': 31449,\n",
       " 'nq9adw5': 88108,\n",
       " 'advisable': 26346,\n",
       " 'ih': 65912,\n",
       " '_motivation_': 24088,\n",
       " 'd7u': 44740,\n",
       " 'scrivener': 105461,\n",
       " 'filipowski': 55343,\n",
       " 'lni': 76487,\n",
       " 'venizelos': 121099,\n",
       " 'jing': 70139,\n",
       " '4804': 14016,\n",
       " 'acpdgohawa': 25856,\n",
       " 'tilde': 115106,\n",
       " '7380': 18820,\n",
       " 'watercooled': 123347,\n",
       " 'math205': 79809,\n",
       " 'set_values': 106277,\n",
       " 'vessel': 121277,\n",
       " 'suffers': 111577,\n",
       " 'jzlb8': 71269,\n",
       " 'ethic': 52682,\n",
       " 'rankin': 99277,\n",
       " 'sq9': 109729,\n",
       " 'g2o_dx': 57671,\n",
       " 'byf': 35997,\n",
       " '1z6ei4': 8247,\n",
       " '6_7z2nq3': 17349,\n",
       " 'angles': 28248,\n",
       " 'rljfrj': 102396,\n",
       " 'mq2w64f5': 84147,\n",
       " 'c4qav2': 36261,\n",
       " 'treatment': 116382,\n",
       " 'irz205': 68528,\n",
       " 'i860s': 65299,\n",
       " 'beekeeper': 32483,\n",
       " 'messianic': 81280,\n",
       " 'j7kec': 69256,\n",
       " 'earn': 50115,\n",
       " '165655': 5279,\n",
       " 'appreaciated': 28924,\n",
       " 'dotted': 48687,\n",
       " 'kneeus': 73157,\n",
       " 'hst': 64490,\n",
       " 'ide_drive_controls_iochrdy': 65676,\n",
       " 'c5l15a': 36719,\n",
       " 'decide': 45644,\n",
       " 'linscott': 76076,\n",
       " 'corp': 42708,\n",
       " 'ausable': 30437,\n",
       " 'viamar': 121406,\n",
       " 'iqvei': 68358,\n",
       " 'tashkin': 113521,\n",
       " 'tcsteven': 113685,\n",
       " 'memorable': 81055,\n",
       " 'lyg': 77483,\n",
       " 'thankfully': 114426,\n",
       " '2yyk9': 11369,\n",
       " 'mycallingprog': 85377,\n",
       " 'vmk80': 121905,\n",
       " 'doled': 48494,\n",
       " '23722': 9412,\n",
       " 'pocomoco': 94679,\n",
       " 'hostile': 64102,\n",
       " 'guildenstern': 60834,\n",
       " 'frenchies': 56861,\n",
       " 'dkfox': 48169,\n",
       " 'wmxgx': 124812,\n",
       " 'c5otox': 36805,\n",
       " 'n1nzu': 85631,\n",
       " 'reuse': 101566,\n",
       " 'undercorrection': 118572,\n",
       " 'abvious': 25509,\n",
       " '_009': 23114,\n",
       " 'g9134255': 57820,\n",
       " 'myvo': 85490,\n",
       " 'c1jwox': 36136,\n",
       " 'documentation': 48415,\n",
       " '41p5q197a': 13512,\n",
       " 'uqs7': 119600,\n",
       " 'indicate': 66890,\n",
       " 'edmondson': 50504,\n",
       " '2gn3z3': 10801,\n",
       " 'orbital': 90279,\n",
       " 'therapies_': 114573,\n",
       " 'q2gg7': 97402,\n",
       " 'retries': 101525,\n",
       " 'gleeful': 59361,\n",
       " '27916070': 10131,\n",
       " 'condos': 41795,\n",
       " '67avj': 17150,\n",
       " 'shortly': 107001,\n",
       " 'g48f': 57726,\n",
       " 'freemant': 56818,\n",
       " '3456': 11947,\n",
       " '2sax': 11148,\n",
       " 'repair': 100949,\n",
       " 'credence': 43333,\n",
       " 'mwzc': 85277,\n",
       " 'itcorp': 68798,\n",
       " 'yeian': 128048,\n",
       " 'machining': 78656,\n",
       " 'crate': 43261,\n",
       " 'overlaying': 91023,\n",
       " 'adsp': 26274,\n",
       " 'pda': 92629,\n",
       " '17989': 5774,\n",
       " 'tailed': 113244,\n",
       " 'mumblings': 84885,\n",
       " 'c5t05k': 36936,\n",
       " 'livy': 76258,\n",
       " '41': 13455,\n",
       " '313030': 11573,\n",
       " 'roderic': 102759,\n",
       " 'pigpens': 93842,\n",
       " 'achieving': 25782,\n",
       " 'a1200': 24679,\n",
       " 'horny': 64030,\n",
       " 'c4y976': 36329,\n",
       " 'c5elp2': 36523,\n",
       " '7p2j': 19746,\n",
       " 'rlb_vl': 102316,\n",
       " 'acad2': 25541,\n",
       " 'smerdis': 108308,\n",
       " 'babecki': 31370,\n",
       " 'insurgents': 67663,\n",
       " 'sborders': 104879,\n",
       " '2__': 10524,\n",
       " 'okh8': 89616,\n",
       " 'futher': 57385,\n",
       " 'l4ne': 74145,\n",
       " 'fergie': 54917,\n",
       " 'constellation': 42155,\n",
       " 'uplink': 119510,\n",
       " 'wp3d': 125142,\n",
       " '3877': 12460,\n",
       " 'mening': 81102,\n",
       " '277v': 10113,\n",
       " 'willy': 124374,\n",
       " 'hawkeye': 62251,\n",
       " 'b9d': 31281,\n",
       " 'spanish': 109125,\n",
       " 'r0e06c': 98635,\n",
       " 'freebairn': 56804,\n",
       " 'behind': 32576,\n",
       " 'gotcha': 59862,\n",
       " '13738': 4057,\n",
       " 'emai': 51267,\n",
       " 'delino': 46119,\n",
       " 'israelists': 68697,\n",
       " 'rnp': 102582,\n",
       " 'postalunion': 95140,\n",
       " 'belaboring': 32613,\n",
       " 'winsorr': 124527,\n",
       " 'egerter': 50703,\n",
       " 'bazaar': 32137,\n",
       " 'guzzis': 61001,\n",
       " 'wate': 123344,\n",
       " 'ss3rhsq': 109969,\n",
       " 'genealogical': 58582,\n",
       " 'ncmc': 86335,\n",
       " 'page': 91685,\n",
       " '36ec': 12277,\n",
       " 'uhc': 118025,\n",
       " 'lofton': 76603,\n",
       " 'fashion': 54454,\n",
       " 'w9v4c': 122920,\n",
       " 'networks': 86757,\n",
       " 'superciliousness': 111859,\n",
       " '67037': 17116,\n",
       " '1352': 4005,\n",
       " 'aj': 27035,\n",
       " 'scout': 105374,\n",
       " 'lwu': 77437,\n",
       " 'interchange': 67766,\n",
       " '130430': 3823,\n",
       " 'moc': 83226,\n",
       " 'rectangles': 100133,\n",
       " '1z': 8226,\n",
       " 'qou': 97980,\n",
       " 'prairie': 95413,\n",
       " '4ezb': 14350,\n",
       " 'miniscribe': 82263,\n",
       " '10660': 2780,\n",
       " 'du': 49297,\n",
       " 'revolves': 101668,\n",
       " 'ceee': 38542,\n",
       " '4u1': 14750,\n",
       " 'thud': 114925,\n",
       " 'os4': 90554,\n",
       " 'railways': 99119,\n",
       " 'ld2vyd': 74960,\n",
       " 'gp2011': 59937,\n",
       " 'wmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmwmw': 124808,\n",
       " 'sport': 109575,\n",
       " '93apr12204254': 21874,\n",
       " 'davydov': 45284,\n",
       " 'n5gjm': 85722,\n",
       " '8i9': 21050,\n",
       " 'lf': 75511,\n",
       " 'independantly': 66858,\n",
       " 'sod': 108630,\n",
       " 'opal12': 90011,\n",
       " 'hips': 63312,\n",
       " 'hodges': 63656,\n",
       " 'passages': 92243,\n",
       " '566ev': 15498,\n",
       " '153552': 4779,\n",
       " '3hzd9': 12870,\n",
       " 'sgcl1': 106438,\n",
       " 'cbnewsi': 38316,\n",
       " 'kl3100': 72998,\n",
       " 'ejection': 50906,\n",
       " 'moree': 83710,\n",
       " 'shelf': 106738,\n",
       " 'detrimental': 46772,\n",
       " 'matusevich': 79894,\n",
       " 'otj': 90705,\n",
       " 'yua8yucgbo': 128566,\n",
       " 'mcucs': 80504,\n",
       " '9250': 21687,\n",
       " 'hmcvax': 63527,\n",
       " 'fridy': 56903,\n",
       " 'petcocks': 93243,\n",
       " 'eyeball': 53670,\n",
       " 'qk6e': 97852,\n",
       " '118': 3339,\n",
       " 'qvpd': 98543,\n",
       " 't8': 113042,\n",
       " 'waldensoftware': 123095,\n",
       " 'metaflow': 81311,\n",
       " 'communucations': 41333,\n",
       " 'directional': 47433,\n",
       " 'dalacin': 44907,\n",
       " 'bitplanes': 33551,\n",
       " 'orpington': 90498,\n",
       " 'trailering': 116091,\n",
       " 'pc4170e': 92558,\n",
       " '_decreases_': 23687,\n",
       " '48fje': 14099,\n",
       " 'u36qm': 117498,\n",
       " 'gcqm': 58402,\n",
       " '54yrogyua46': 15341,\n",
       " 'interrogationum': 67934,\n",
       " 'microcircuit': 81846,\n",
       " 'i0mf': 65101,\n",
       " 'gasser': 58224,\n",
       " 'ratio': 99379,\n",
       " 'du48536mx2543': 49301,\n",
       " 'muharrerat': 84752,\n",
       " 'wjbc': 124690,\n",
       " 'outscore': 90885,\n",
       " 'burmeister': 35715,\n",
       " '19470': 6335,\n",
       " '65c02p3': 16972,\n",
       " '30x4': 11543,\n",
       " '1q96tpinnpcn': 7394,\n",
       " 'ty83c': 117260,\n",
       " 'redish': 100211,\n",
       " 'turbodos': 116990,\n",
       " 'gro': 60448,\n",
       " 'concealibility': 41663,\n",
       " 'std_disclaimer': 110435,\n",
       " 'burghardt': 35692,\n",
       " 'lan': 74478,\n",
       " 'ayari': 30894,\n",
       " '94000': 22014,\n",
       " 'versatile': 121227,\n",
       " 'micom': 81830,\n",
       " 'esp': 52516,\n",
       " 'wingnut': 124476,\n",
       " '7950': 19379,\n",
       " 'intdg': 67679,\n",
       " 'ajax': 27050,\n",
       " 'celebrate': 38563,\n",
       " 'txr': 117246,\n",
       " 'stephanopolous': 110562,\n",
       " '1600': 5024,\n",
       " 'turquoise': 117054,\n",
       " 'mechanical': 80749,\n",
       " 'rusinow': 103561,\n",
       " 'o5um': 88786,\n",
       " 'shimpei': 106839,\n",
       " 'paradise': 91972,\n",
       " 'c1pp': 36145,\n",
       " 'vertical': 121251,\n",
       " 'unwitting': 119384,\n",
       " 'ux4': 120130,\n",
       " 'carden': 37822,\n",
       " '752x580': 18983,\n",
       " '0_zs': 1608,\n",
       " 'wavs': 123409,\n",
       " 'abdel': 25288,\n",
       " 'smallish': 108257,\n",
       " 'cpplzu0': 43133,\n",
       " 'ujl2s': 118124,\n",
       " 'koreans': 73409,\n",
       " 'stephan_lebeau': 110557,\n",
       " 'qumran': 98455,\n",
       " 'infante': 67060,\n",
       " 'egon': 50725,\n",
       " 'modernized': 83295,\n",
       " 'disagreements': 47480,\n",
       " 'a_lv': 25048,\n",
       " 'm8qw': 78345,\n",
       " 'fiu': 55590,\n",
       " 'jamesdon': 69465,\n",
       " 'smaug': 108284,\n",
       " 'preeminent': 95593,\n",
       " 'establishment': 52577,\n",
       " 'tseng4000': 116765,\n",
       " 'christan': 39585,\n",
       " 'hennard': 62773,\n",
       " 'sm10': 108231,\n",
       " 't_ay': 113102,\n",
       " 'jagst18': 69431,\n",
       " 'bs3': 35292,\n",
       " 'deviousness': 46851,\n",
       " 'back': 31414,\n",
       " 'kpikzsfj': 73511,\n",
       " 'crucis': 43614,\n",
       " 'xav': 126136,\n",
       " 'wwq': 125540,\n",
       " 'krispy': 73617,\n",
       " 'vtt': 122321,\n",
       " '29312': 10427,\n",
       " 'nt_': 88267,\n",
       " 'j1rchz': 69097,\n",
       " 'mentioning': 81134,\n",
       " 'pc7ygm5': 92563,\n",
       " 'prison': 95981,\n",
       " '1r_': 7964,\n",
       " 'sleeve': 108059,\n",
       " 'gg445u': 58916,\n",
       " 'conductivity': 41803,\n",
       " 'cardiology': 37834,\n",
       " 'uoi': 119410,\n",
       " 'yy0h': 128715,\n",
       " '010734': 420,\n",
       " 'writes': 125271,\n",
       " 'reincarnation': 100546,\n",
       " 'mnf': 83115,\n",
       " 'farul': 54437,\n",
       " '24eq45': 9633,\n",
       " 'xzz0280': 127587,\n",
       " 'kghz7': 72436,\n",
       " 'mircea': 82336,\n",
       " 'reliant': 100694,\n",
       " 'jccc': 69655,\n",
       " 'cheeper': 39196,\n",
       " 'christanity': 39586,\n",
       " 'b8fnb': 31244,\n",
       " 'mt3p': 84553,\n",
       " '1fyl': 6874,\n",
       " 'mammoth': 79177,\n",
       " 'ob5juz_9': 88943,\n",
       " 'utas': 119870,\n",
       " 'xptablechildposition': 126871,\n",
       " 'ucns': 117836,\n",
       " '145s145s17': 4459,\n",
       " 'engelbert': 51717,\n",
       " 'moyne': 84022,\n",
       " 'lani': 74552,\n",
       " 'runar': 103509,\n",
       " 'creep': 43353,\n",
       " 'maccontent': 78615,\n",
       " 'k94j1g': 71565,\n",
       " 'gcx_s': 58423,\n",
       " 'romanian': 102867,\n",
       " 'jzv': 71317,\n",
       " 'qqy': 98032,\n",
       " '171250': 5524,\n",
       " 'k5i': 71449,\n",
       " '3hbj': 12813,\n",
       " 'mediocrity': 80826,\n",
       " 'hebert': 62538,\n",
       " 'dbl50872': 45353,\n",
       " '4380': 13656,\n",
       " '162820': 5158,\n",
       " 'mankind': 79295,\n",
       " 'qjvl': 97845,\n",
       " 'bordeaux': 34432,\n",
       " 'vutbr': 122390,\n",
       " 'ns16450': 88187,\n",
       " 'med4': 80783,\n",
       " 'periodicals': 93035,\n",
       " 'e_8': 50032,\n",
       " 'aircraft': 26955,\n",
       " 'wijzigingen': 124293,\n",
       " 'y30': 127651,\n",
       " 'diehard': 47159,\n",
       " 'g79': 57787,\n",
       " 'q90nf_g': 97582,\n",
       " 'cableco': 37258,\n",
       " 'testbed': 114246,\n",
       " '46j': 13908,\n",
       " 'ozkwjd': 91274,\n",
       " 'ren': 100855,\n",
       " 'abput': 25411,\n",
       " 'incendiary': 66686,\n",
       " 'unimpressed': 118880,\n",
       " 'stabilise': 110124,\n",
       " 'rippling': 102105,\n",
       " 'devlet': 46856,\n",
       " 'liyetze': 76260,\n",
       " 'aax': 25231,\n",
       " 'o4rfpta874rm2e': 88748,\n",
       " '551551': 15359,\n",
       " 'courtney': 42984,\n",
       " 'lorimer': 76792,\n",
       " 'dvr': 49595,\n",
       " 'lgm': 75568,\n",
       " 'minimised': 82249,\n",
       " 'squalor': 109777,\n",
       " 'iha5': 65922,\n",
       " 'mbhi8bea': 80106,\n",
       " 'relations': 100640,\n",
       " 'neu': 86764,\n",
       " 'vorobyev': 122114,\n",
       " 'flashers': 55752,\n",
       " 'easiest': 50147,\n",
       " 'portraits': 95058,\n",
       " 'gnb': 59553,\n",
       " '1qkmkiinnep3': 7555,\n",
       " 'purported': 97076,\n",
       " '195002': 6347,\n",
       " 'apologeticist': 28778,\n",
       " 'nonononnononono': 87775,\n",
       " 'ag3zr2': 26636,\n",
       " '7k': 19660,\n",
       " 'maritime': 79500,\n",
       " 'mc8rlimrchzeg': 80224,\n",
       " '6258': 16693,\n",
       " 'icoons1': 65595,\n",
       " '6m3b': 17794,\n",
       " 'eulenbrg': 52787,\n",
       " 'swim': 112386,\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO not add irrelevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15593"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sparse arrays to avoid storing lots of zeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(count_vectorizer.transform(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25346280"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(count_vectorizer.transform(X[0:1]).toarray())s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.transform(X[0:1]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = sklearn.linear_model.Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.fit(count_vectorizer.transform(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = perceptron.predict(count_vectorizer.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268516881739438"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_preds  == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-gram use\n",
    "\n",
    "We can add n-grams into our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130107"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130107"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=754, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = sklearn.linear_model.Perceptron(random_state=754)\n",
    "perceptron.fit(count_vectorizer.transform(X),y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924076365564787"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == perceptron.predict(count_vectorizer.transform(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr,y_te = sklearn.model_selection.train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8485, 8485, 2829, 2829, 11314)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tr), len(y_tr), len(X_te), len(y_te), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=754, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = sklearn.linear_model.Perceptron(random_state=754)\n",
    "perceptron.fit(count_vectorizer.transform(X_tr),y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759575721862109"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_tr == perceptron.predict(count_vectorizer.transform(X_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352774832096147"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_te == perceptron.predict(count_vectorizer.transform(X_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our own perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_tr_array = count_vectorizer.transform(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8485x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1330356 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MulticlassPerceptron():\n",
    "\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, X, W, b):\n",
    "\n",
    "        n_examples = X.shape[0]\n",
    "        y_hat = np.zeros(n_examples)\n",
    "        for n in range(n_examples):\n",
    "            y_scores = predict_scores(X[n],W,b)\n",
    "            y_hat[n] = np.argmax(y_scores)\n",
    "\n",
    "        return y_hat\n",
    "        #y_scores = predict_scores(X,W,b)\n",
    "        #return np.argmax(y_scores, axis=1)\n",
    "\n",
    "    def predict_scores(self, x,W,b):\n",
    "        return np.dot(W,x) + b\n",
    "        #return np.dot(W,x.T).T + b\n",
    "\n",
    "    def fit(self, X,Y):\n",
    "\n",
    "        n_examples, n_features = X.shape\n",
    "        n_classes = len(set(Y))\n",
    "        learning_rate = 1\n",
    "        n_epochs = 10\n",
    "\n",
    "        W = np.random.random([n_classes, n_features])\n",
    "        b = np.zeros(n_classes)\n",
    "        \n",
    "        accuracy_per_epoch = []\n",
    "        for epoch in range(n_epochs):\n",
    "            for x,y in zip(X,Y):\n",
    "                y_scores = self.predict_scores(x, W, b)\n",
    "                y_hat = np.argmax(y_scores)\n",
    "\n",
    "                if y_hat != y:\n",
    "                    W[y_hat,:] = W[y_hat,:] - x * learning_rate \n",
    "                    b[y_hat]   = b[y_hat]   - learning_rate \n",
    "                    W[y,:]     = W[y, :] + x * learning_rate \n",
    "                    b[y]       = b[y]    + learning_rate \n",
    "            \n",
    "            y_preds = np.argmax(W*X + b, axis=1)\n",
    "            current_accuracy = np.mean(y_preds == Y)\n",
    "            accuracy_per_epoch.append(current_accuracy)\n",
    "            #print(f\"epoch: {epoch} current accuracy: {current_accuracy}\")\n",
    "            print(\"epoch: {} current accuracy: {}\".format(epoch,current_accuracy))\n",
    "            \n",
    "        return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "mperceptron = MulticlassPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mperceptron.fit(X_tr_array, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
